{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'mean_absolute_percentage_error' from 'sklearn.metrics' (C:\\Users\\shav.vimelindiran\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2c7119d0882c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_absolute_percentage_error\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'mean_absolute_percentage_error' from 'sklearn.metrics' (C:\\Users\\shav.vimelindiran\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "TFT_encoding_predictions = np.load('../data/model_preds/TFT_encoded_predictions.npy', allow_pickle=True)\n",
    "TFT_predictions = np.load('../data/model_preds/TFT_predictions.npy', allow_pickle=True)\n",
    "LSTM_predictions = np.load('../data/model_preds/LSTM_predictions.npy', allow_pickle=True)\n",
    "ARIMA_predictions = np.load('../data/model_preds/ARIMA_predictions.npy', allow_pickle=True)\n",
    "naive_predictions = np.load('../data/model_preds/naive_predictions.npy', allow_pickle=True)\n",
    "tests = np.load('../data/model_preds/actual_sales.npy', allow_pickle=True)\n",
    "data = pd.read_csv('../data/data_processed_plant_item_10_03_22.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifications = np.load('forecast_classification.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ensemble_preds(clf, TFT_preds_clf):\n",
    "    TFT_ensemble_predictions = np.zeros((len(clf), 6))\n",
    "    for i in range(len(clf)):\n",
    "        if clf[i] == 0:\n",
    "            TFT_ensemble_predictions[i, :] = np.zeros((6))\n",
    "        else:\n",
    "            TFT_ensemble_predictions[i, :] = TFT_preds_clf[i, :]\n",
    "    return TFT_ensemble_predictions\n",
    "#TFT_ensemble_predictions =create_ensemble_preds(classifications, TFT_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFT encodings\n",
      "\n",
      "mean squared error:                               30747.87\n",
      "mean absolute error:                              35.11\n",
      "mean absolute percentage error:           4.64 %\n",
      "mean absolute percentage error weighted:  71.48 %\n",
      "\n",
      "TFT\n",
      "\n",
      "mean squared error:                               28831.01\n",
      "mean absolute error:                              34.45\n",
      "mean absolute percentage error:           4.54 %\n",
      "mean absolute percentage error weighted:  70.13 %\n",
      "\n",
      "LSTM\n",
      "\n",
      "mean squared error:                               151461.38\n",
      "mean absolute error:                              79.53\n",
      "mean absolute percentage error:           22.0 %\n",
      "mean absolute percentage error weighted:  161.91 %\n",
      "\n",
      "ARIMA\n",
      "\n",
      "mean squared error:                               40993.61\n",
      "mean absolute error:                              38.72\n",
      "mean absolute percentage error:           4.47 %\n",
      "mean absolute percentage error weighted:  78.82 %\n",
      "\n",
      "naive\n",
      "\n",
      "mean squared error:                               41915.37\n",
      "mean absolute error:                              40.57\n",
      "mean absolute percentage error:           3.35 %\n",
      "mean absolute percentage error weighted:  82.59 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def WMAPE_calc(preds, tests):\n",
    "    flat_pred = np.array(preds).flatten()\n",
    "    flat_test = np.array(tests).flatten()\n",
    "    residuals = []\n",
    "    for i in range(len(flat_pred)):\n",
    "        residuals.append(abs(flat_test[i] - flat_pred[i]))\n",
    "    WMAPE = 100 * (np.sum(residuals) / np.sum(flat_test))\n",
    "    return WMAPE\n",
    "\n",
    "def WMAPE2_calc(preds, tests):\n",
    "    preds = preds + 1\n",
    "    tests = tests + 1\n",
    "    total_vol = np.sum(tests)\n",
    "    residuals = 0\n",
    "    total_vol = np.sum(tests)\n",
    "    for i in range(preds.shape[0]):\n",
    "        pred = preds[i, :]\n",
    "        for t in range(len(pred)):\n",
    "            residuals += abs(pred[t] - tests[i, t])\n",
    "    WMAPE_2 = (np.sum(residuals) / total_vol) * 100\n",
    "    return WMAPE_2\n",
    "\n",
    "def metric_test(preds, tests):\n",
    "    MSEs = []\n",
    "    MAPEs = []\n",
    "    MAE = []\n",
    "    for i in range(preds.shape[0]):\n",
    "        pred = preds[i, :]\n",
    "        test = tests[i, :]\n",
    "        MSEs.append(mean_squared_error(test, pred))\n",
    "        MAPEs.append(mean_absolute_percentage_error(test + 1, pred + 1))\n",
    "        MAE.append(mean_absolute_error(test, pred))\n",
    "    WMAPE = WMAPE_calc(preds, tests)\n",
    "    WMAPE_2 = WMAPE2_calc(preds, tests)\n",
    "    #WMAPE_2 = WMAPE_calc_2(preds, tests)\n",
    "    print('mean squared error:                              ', round(np.mean(MSEs), 2))\n",
    "    print('mean absolute error:                             ', round(np.mean(MAE), 2))\n",
    "    print('mean absolute percentage error:          ', round(np.mean(MAPEs), 2), '%')\n",
    "    #print('mean absolute percentage error weighted: ', round(WMAPE, 2), '%')\n",
    "    print('mean absolute percentage error weighted: ', round(WMAPE_2, 2), '%')\n",
    "\n",
    "def compare_performance(model_dict, tests):\n",
    "    for model in list(model_dict.keys()):\n",
    "        print(model)\n",
    "        print('')\n",
    "        metric_test(model_dict[model], tests)\n",
    "        print('')\n",
    "\n",
    "\n",
    "model_dict = {'TFT encodings':TFT_encoding_predictions, 'TFT':TFT_predictions, 'LSTM':LSTM_predictions, 'ARIMA':ARIMA_predictions, 'naive':naive_predictions}\n",
    "compare_performance(model_dict, tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[203.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.  10.   3.   0.   0.]\n",
      " [  0.   0.   8.   8.   4.   1.]\n",
      " [  0.  40.  38.   0.  78.  42.]]\n"
     ]
    }
   ],
   "source": [
    "print(tests[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_over_plants(array, data):\n",
    "    timeseries_list = list(data['timeseries'].unique())\n",
    "    item_dict = {}\n",
    "    for i in range(len(timeseries_list)):\n",
    "        timeseries = data[data['timeseries'] == timeseries_list[i]]\n",
    "        itemID = list(timeseries['ParentItemID'].unique())[0]\n",
    "        if itemID not in list(item_dict.keys()):\n",
    "            item_dict[itemID] = array[i, :]\n",
    "        else:\n",
    "            prev_vol = item_dict[itemID]\n",
    "            #print(prev_vol)\n",
    "            #print(array[i, :])\n",
    "            new_vol = prev_vol + array[i, :]\n",
    "            #print(new_vol)\n",
    "            #print('')\n",
    "            item_dict[itemID] = new_vol\n",
    "    print(len(list(item_dict.keys())))\n",
    "    print(len(data['ParentItemID'].unique()))\n",
    "    print('')\n",
    "    return item_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068\n",
      "1068\n",
      "\n",
      "1068\n",
      "1068\n",
      "\n",
      "1068\n",
      "1068\n",
      "\n",
      "1068\n",
      "1068\n",
      "\n",
      "1068\n",
      "1068\n",
      "\n",
      "1068\n",
      "1068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_item_dict = sum_over_plants(tests, data)\n",
    "ARIMA_preds_dict = sum_over_plants(ARIMA_predictions, data)\n",
    "TFT_encodings_preds_dict = sum_over_plants(TFT_encoding_predictions, data)\n",
    "TFT_preds_dict = sum_over_plants(TFT_predictions, data)\n",
    "LSTM_preds_dict = sum_over_plants(LSTM_predictions, data)\n",
    "naive_preds_dict = sum_over_plants(naive_predictions, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WMAPE2_calc(pred_dict, test_dict, model):\n",
    "    residuals = 0\n",
    "    total_vol = np.sum(list(test_dict.values()))\n",
    "    for itemID in list(pred_dict.keys()):\n",
    "        pred = pred_dict[itemID] + 0.1\n",
    "        test = test_dict[itemID] + 0.1\n",
    "        for t in range(len(pred)):\n",
    "            residuals += abs(pred[t] - test[t])\n",
    "    WMAPE_2 = (np.sum(residuals) / total_vol) * 100\n",
    "    print('Weighted and aggregated MAPE for:', model, ':', round(WMAPE_2, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted and aggregated MAPE for: TFT encodings : 57.05 %\n",
      "Weighted and aggregated MAPE for: TFT : 54.63 %\n",
      "Weighted and aggregated MAPE for: LSTM : 131.94 %\n",
      "Weighted and aggregated MAPE for: ARIMA : 60.13 %\n",
      "Weighted and aggregated MAPE for: Naive : 62.37 %\n"
     ]
    }
   ],
   "source": [
    "models = ['TFT encodings', 'TFT', 'LSTM', 'ARIMA', 'Naive']\n",
    "WMAPE2_calc(TFT_encodings_preds_dict, test_item_dict, models[0])\n",
    "WMAPE2_calc(TFT_preds_dict, test_item_dict, models[1])\n",
    "WMAPE2_calc(LSTM_preds_dict, test_item_dict, models[2])\n",
    "WMAPE2_calc(ARIMA_preds_dict, test_item_dict, models[3])\n",
    "WMAPE2_calc(naive_preds_dict, test_item_dict, models[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "39107c45289741facd1c574d4c3f3f1db037868d86098ed4da8abb8e076ff11e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
